{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1475333",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-07-28T09:54:59.334250Z",
     "iopub.status.busy": "2025-07-28T09:54:59.333920Z",
     "iopub.status.idle": "2025-07-28T09:55:17.132714Z",
     "shell.execute_reply": "2025-07-28T09:55:17.131515Z"
    },
    "id": "6_DXemf5N4jX",
    "outputId": "3c123171-ad90-4ae6-9097-f2c300e39676",
    "papermill": {
     "duration": 17.829727,
     "end_time": "2025-07-28T09:55:17.134292",
     "exception": false,
     "start_time": "2025-07-28T09:54:59.304565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-07-28 09:54:59--  https://github.com/liberationfonts/liberation-fonts.git\r\n",
      "Resolving github.com (github.com)... 140.82.121.4\r\n",
      "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\r\n",
      "Location: https://github.com/liberationfonts/liberation-fonts [following]\r\n",
      "--2025-07-28 09:54:59--  https://github.com/liberationfonts/liberation-fonts\r\n",
      "Reusing existing connection to github.com:443.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: unspecified [text/html]\r\n",
      "Saving to: ‘LiberationSans-Regular.ttf’\r\n",
      "\r\n",
      "LiberationSans-Regu     [ <=>                ] 273.50K  --.-KB/s    in 0.03s   \r\n",
      "\r\n",
      "2025-07-28 09:55:00 (9.00 MB/s) - ‘LiberationSans-Regular.ttf’ saved [280060]\r\n",
      "\r\n",
      "✅ Font downloaded.\n",
      "Collecting faker\r\n",
      "  Downloading faker-37.4.2-py3-none-any.whl.metadata (15 kB)\r\n",
      "Requirement already satisfied: tzdata in /usr/local/lib/python3.11/dist-packages (from faker) (2025.2)\r\n",
      "Downloading faker-37.4.2-py3-none-any.whl (1.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: faker\r\n",
      "Successfully installed faker-37.4.2\r\n",
      "✅ Font file found at: ./LiberationSans-Regular.ttf\n"
     ]
    }
   ],
   "source": [
    "!wget \"https://github.com/liberationfonts/liberation-fonts.git\" -O LiberationSans-Regular.ttf\n",
    "print(\"✅ Font downloaded.\")\n",
    "\n",
    "!pip install faker\n",
    "# python -m pip install Faker\n",
    "# Step 3: Import all necessary modules\n",
    "import random\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from faker import Faker\n",
    "from albumentations import Compose, Rotate, GaussNoise, Blur\n",
    "from datasets import Dataset\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# --- Configuration ---\n",
    "fake = Faker()\n",
    "Faker.seed(42)\n",
    "\n",
    "# CORRECTED: Use the direct path to the single font we just downloaded.\n",
    "FONT_PATH = './LiberationSans-Regular.ttf'\n",
    "\n",
    "# Check if the font file exists\n",
    "if os.path.exists(FONT_PATH):\n",
    "    print(f\"✅ Font file found at: {FONT_PATH}\")\n",
    "else:\n",
    "    # This error should not occur with the new download method.\n",
    "    print(f\"❌ Font file not found at: {FONT_PATH}. There might be a network issue.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e9ff779",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T09:55:17.186162Z",
     "iopub.status.busy": "2025-07-28T09:55:17.185616Z",
     "iopub.status.idle": "2025-07-28T09:55:17.201950Z",
     "shell.execute_reply": "2025-07-28T09:55:17.201242Z"
    },
    "id": "W8WHWm6VN4jY",
    "papermill": {
     "duration": 0.043423,
     "end_time": "2025-07-28T09:55:17.203297",
     "exception": false,
     "start_time": "2025-07-28T09:55:17.159874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_text_image(text, font_path):\n",
    "    \"\"\"Generates an image of text using the downloaded font.\"\"\"\n",
    "    font_size = 22\n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "\n",
    "    dummy_img = Image.new('RGB', (1, 1))\n",
    "    draw = ImageDraw.Draw(dummy_img)\n",
    "    left, top, right, bottom = draw.textbbox((0, 0), text, font=font)\n",
    "    text_width = right - left\n",
    "    text_height = bottom - top\n",
    "\n",
    "    padding = 10\n",
    "    image = Image.new('RGB', (text_width + 2*padding, text_height + 2*padding), 'white')\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    draw.text((padding, padding), text, font=font, fill='black')\n",
    "    return image\n",
    "\n",
    "def generate_table_image(data, title):\n",
    "    \"\"\"Generates an image of a table using matplotlib.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(6, 2.5), dpi=100)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(title, fontweight=\"bold\")\n",
    "\n",
    "    table = ax.table(cellText=data['values'], colLabels=data['headers'], loc='center', cellLoc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    table.scale(1, 1.8)\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    img_rgba = np.frombuffer(fig.canvas.buffer_rgba(), dtype=np.uint8)\n",
    "    img_rgb = img_rgba.reshape(fig.canvas.get_width_height()[::-1] + (4,))[..., :3]\n",
    "    plt.close(fig)\n",
    "    return Image.fromarray(img_rgb)\n",
    "\n",
    "def generate_graph_image(data, title, xlabel, ylabel):\n",
    "    \"\"\"Generates a line graph image using matplotlib.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(6, 4), dpi=100)\n",
    "    ax.plot(data['x'], data['y'], marker='o', color='b')\n",
    "    ax.set_title(title, fontweight=\"bold\", fontsize=14)\n",
    "    ax.set_xlabel(xlabel, fontsize=12)\n",
    "    ax.set_ylabel(ylabel, fontsize=12)\n",
    "    ax.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    img_rgba = np.frombuffer(fig.canvas.buffer_rgba(), dtype=np.uint8)\n",
    "    img_rgb = img_rgba.reshape(fig.canvas.get_width_height()[::-1] + (4,))[..., :3]\n",
    "    plt.close(fig)\n",
    "    return Image.fromarray(img_rgb)\n",
    "\n",
    "# --- Augmentations ---\n",
    "augmentations = Compose([\n",
    "    Rotate(limit=3, p=0.6),\n",
    "    GaussNoise(p=0.4),\n",
    "    Blur(blur_limit=3, p=0.4),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3561acf8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-07-28T09:55:17.257363Z",
     "iopub.status.busy": "2025-07-28T09:55:17.257003Z",
     "iopub.status.idle": "2025-07-28T09:55:35.714796Z",
     "shell.execute_reply": "2025-07-28T09:55:35.713782Z"
    },
    "id": "aI3u3oKBN4jZ",
    "outputId": "ada2c29d-5c25-42ea-984a-fa0ae4e01c70",
    "papermill": {
     "duration": 18.488558,
     "end_time": "2025-07-28T09:55:35.716363",
     "exception": false,
     "start_time": "2025-07-28T09:55:17.227805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 100 synthetic samples...\n",
      "\n",
      "✅ Dataset generation complete.\n"
     ]
    }
   ],
   "source": [
    "# --- Main Data Generation Loop ---\n",
    "def create_instruction_dataset(num_samples=50):\n",
    "    dataset = []\n",
    "    task_types = ['handwriting_ocr', 'table_extraction', 'graph_qa']\n",
    "\n",
    "    print(f\"Generating {num_samples} synthetic samples...\")\n",
    "    for i in range(num_samples):\n",
    "        task = random.choice(task_types)\n",
    "        canvas = Image.new('RGB', (800, 600), 'white')\n",
    "        instruction, answer = \"\", \"\"\n",
    "\n",
    "        header_font = ImageFont.truetype(FONT_PATH, 28)\n",
    "        header_text = \"Community Health Clinic - Patient Record\"\n",
    "        draw = ImageDraw.Draw(canvas)\n",
    "        draw.text((50, 40), header_text, font=header_font, fill='black')\n",
    "        draw.line([(50, 80), (750, 80)], fill='black', width=2)\n",
    "\n",
    "        if task == 'handwriting_ocr':\n",
    "            notes = f\"Doctor's Notes:\\n{fake.paragraph(nb_sentences=3)}\"\n",
    "            text_img = generate_text_image(notes, FONT_PATH)\n",
    "            canvas.paste(text_img, (50, 120))\n",
    "            instruction = \"Transcribe the text under 'Doctor's Notes'.\"\n",
    "            answer = notes.replace(\"Doctor's Notes:\\n\", \"\").strip()\n",
    "\n",
    "        elif task == 'table_extraction':\n",
    "            table_data = {\n",
    "                'headers': ['Test', 'Result', 'Reference Range'],\n",
    "                'values': [\n",
    "                    ['WBC', f\"{random.uniform(4.0, 11.0):.1f} x10^9/L\", '4.0-11.0'],\n",
    "                    ['HGB', f\"{random.uniform(12.0, 16.0):.1f} g/dL\", '12.0-16.0'],\n",
    "                    ['PLT', f\"{random.randint(150, 450)} x10^9/L\", '150-450']\n",
    "                ]\n",
    "            }\n",
    "            table_img = generate_table_image(table_data, \"Complete Blood Count (CBC)\")\n",
    "            canvas.paste(table_img, (100, 150))\n",
    "            instruction = \"Extract the test results for HGB and PLT in JSON format.\"\n",
    "            answer_dict = {\n",
    "                \"HGB\": table_data['values'][1][1],\n",
    "                \"PLT\": table_data['values'][2][1]\n",
    "            }\n",
    "            answer = json.dumps(answer_dict)\n",
    "\n",
    "        elif task == 'graph_qa':\n",
    "            dates = [f'07-{15+d}' for d in range(5)]\n",
    "            glucose_levels = [random.randint(90, 180) for _ in dates]\n",
    "            graph_data = {'x': dates, 'y': glucose_levels}\n",
    "            graph_img = generate_graph_image(graph_data, \"Fasting Glucose Trend (mg/dL)\", \"Date (July 2025)\", \"Glucose Level\")\n",
    "            canvas.paste(graph_img, (100, 120))\n",
    "\n",
    "            qa_idx = random.randint(0, len(dates) - 1)\n",
    "            qa_date = dates[qa_idx]\n",
    "            qa_glucose = glucose_levels[qa_idx]\n",
    "\n",
    "            instruction = f\"What was the patient's fasting glucose level on {qa_date}?\"\n",
    "            answer = f\"{qa_glucose} mg/dL\"\n",
    "\n",
    "        augmented_image_np = augmentations(image=np.array(canvas))['image']\n",
    "        final_image = Image.fromarray(augmented_image_np)\n",
    "\n",
    "        dataset.append({\"image\": final_image, \"instruction\": instruction, \"answer\": answer})\n",
    "\n",
    "    return Dataset.from_list(dataset)\n",
    "\n",
    "# --- Generate the dataset ---\n",
    "my_dataset = create_instruction_dataset(num_samples=100) # Generating 100 samples\n",
    "print(\"\\n✅ Dataset generation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e93abe04",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85,
     "referenced_widgets": [
      "86f3ebb3021f425f80454fff25317514",
      "1dea67690d73490ea504a0efbc437f60",
      "647548c8e5bf4720923d1d399a4a8acc",
      "c5b1f48095a14641a76c40462f8159c6",
      "e2e391992056445e837dcd40e582f026",
      "c33275200db6423ba105739f1da44b3f",
      "ffbfb21bffeb4fb9865c73f9f0e01622",
      "1d230298befb4a8ea816e3f9053358ee",
      "f3db838fc2e242a7b373f1da87619084",
      "ee497fd6cf774ac39b56a313305f7824",
      "fb58919a33a740428ce803bddbc4c121"
     ]
    },
    "execution": {
     "iopub.execute_input": "2025-07-28T09:55:35.767211Z",
     "iopub.status.busy": "2025-07-28T09:55:35.766888Z",
     "iopub.status.idle": "2025-07-28T09:55:47.572131Z",
     "shell.execute_reply": "2025-07-28T09:55:47.571191Z"
    },
    "id": "-FRoRpUwN4ja",
    "outputId": "20e1b564-1298-44b0-863a-72a1cd347604",
    "papermill": {
     "duration": 11.832578,
     "end_time": "2025-07-28T09:55:47.573837",
     "exception": false,
     "start_time": "2025-07-28T09:55:35.741259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a077ebfb9e4c20bf33d4efc2276ace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving samples:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ All 100 samples have been saved to /content/generated_data/\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"/content/generated_data/\"\n",
    "images_dir = os.path.join(output_dir, \"images\")\n",
    "labels_dir = os.path.join(output_dir, \"labels\")\n",
    "\n",
    "os.makedirs(images_dir, exist_ok=True)\n",
    "os.makedirs(labels_dir, exist_ok=True)\n",
    "\n",
    "# --- Loop through the dataset to save each sample ---\n",
    "for i, sample in enumerate(tqdm(my_dataset, desc=\"Saving samples\")):\n",
    "    image = sample['image']\n",
    "    instruction = sample['instruction']\n",
    "    answer = sample['answer']\n",
    "\n",
    "    # Define file paths\n",
    "    image_filename = f\"sample_{i+1}.png\"\n",
    "    label_filename = f\"sample_{i+1}.json\"\n",
    "\n",
    "    image_path = os.path.join(images_dir, image_filename)\n",
    "    label_path = os.path.join(labels_dir, label_filename)\n",
    "\n",
    "    # Save the image\n",
    "    image.save(image_path)\n",
    "\n",
    "    # Save the instruction and answer in a JSON file\n",
    "    label_data = {\n",
    "        \"instruction\": instruction,\n",
    "        \"answer\": answer\n",
    "    }\n",
    "    with open(label_path, 'w') as f:\n",
    "        json.dump(label_data, f, indent=4)\n",
    "\n",
    "print(f\"\\n✅ All {len(my_dataset)} samples have been saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f8e0d8b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2025-07-28T09:55:47.625029Z",
     "iopub.status.busy": "2025-07-28T09:55:47.624420Z",
     "iopub.status.idle": "2025-07-28T09:59:16.327046Z",
     "shell.execute_reply": "2025-07-28T09:59:16.325411Z"
    },
    "id": "JsxBdK3MN4ja",
    "outputId": "f0adb224-6d93-4813-ce66-96ffc5bb8039",
    "papermill": {
     "duration": 208.729895,
     "end_time": "2025-07-28T09:59:16.328886",
     "exception": false,
     "start_time": "2025-07-28T09:55:47.598991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.6.0+cu124\r\n",
      "Uninstalling torch-2.6.0+cu124:\r\n",
      "  Successfully uninstalled torch-2.6.0+cu124\r\n",
      "Found existing installation: torchvision 0.21.0+cu124\r\n",
      "Uninstalling torchvision-0.21.0+cu124:\r\n",
      "  Successfully uninstalled torchvision-0.21.0+cu124\r\n",
      "Found existing installation: torchaudio 2.6.0+cu124\r\n",
      "Uninstalling torchaudio-2.6.0+cu124:\r\n",
      "  Successfully uninstalled torchaudio-2.6.0+cu124\r\n",
      "Found existing installation: transformers 4.52.4\r\n",
      "Uninstalling transformers-4.52.4:\r\n",
      "  Successfully uninstalled transformers-4.52.4\r\n",
      "Found existing installation: accelerate 1.8.1\r\n",
      "Uninstalling accelerate-1.8.1:\r\n",
      "  Successfully uninstalled accelerate-1.8.1\r\n",
      "\u001b[33mWARNING: Skipping bitsandbytes as it is not installed.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mFound existing installation: peft 0.15.2\r\n",
      "Uninstalling peft-0.15.2:\r\n",
      "  Successfully uninstalled peft-0.15.2\r\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu121\r\n",
      "Collecting torch==2.3.0\r\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torch-2.3.0%2Bcu121-cp311-cp311-linux_x86_64.whl (781.0 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.0/781.0 MB\u001b[0m \u001b[31m908.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting torchvision==0.18.0\r\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.18.0%2Bcu121-cp311-cp311-linux_x86_64.whl (7.0 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting torchaudio==2.3.0\r\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.3.0%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (3.18.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (4.14.0)\r\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (1.13.1)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (2025.5.1)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.0)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.0)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.0)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.0)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.0)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.0)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.0)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.0)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.0)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.0)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting triton==2.3.0 (from torch==2.3.0)\r\n",
      "  Downloading https://download.pytorch.org/whl/triton-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.18.0) (1.26.4)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.18.0) (11.2.1)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0) (12.5.82)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.3.0) (3.0.2)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.18.0) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.18.0) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.18.0) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.18.0) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.18.0) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.18.0) (2.4.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.3.0) (1.3.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision==0.18.0) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision==0.18.0) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision==0.18.0) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision==0.18.0) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision==0.18.0) (2024.2.0)\r\n",
      "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchaudio, torchvision\r\n",
      "  Attempting uninstall: triton\r\n",
      "    Found existing installation: triton 3.2.0\r\n",
      "    Uninstalling triton-3.2.0:\r\n",
      "      Successfully uninstalled triton-3.2.0\r\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\r\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.4.127\r\n",
      "    Uninstalling nvidia-nvtx-cu12-12.4.127:\r\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\r\n",
      "  Attempting uninstall: nvidia-nccl-cu12\r\n",
      "    Found existing installation: nvidia-nccl-cu12 2.21.5\r\n",
      "    Uninstalling nvidia-nccl-cu12-2.21.5:\r\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\r\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, which is not installed.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.3.0+cu121 torchaudio-2.3.0+cu121 torchvision-0.18.0+cu121 triton-2.3.0\r\n",
      "Collecting transformers==4.41.2\r\n",
      "  Downloading transformers-4.41.2-py3-none-any.whl.metadata (43 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting accelerate==0.30.1\r\n",
      "  Downloading accelerate-0.30.1-py3-none-any.whl.metadata (18 kB)\r\n",
      "Collecting bitsandbytes==0.43.1\r\n",
      "  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\r\n",
      "Collecting peft==0.11.1\r\n",
      "  Downloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (3.18.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (0.33.1)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (2024.11.6)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (2.32.4)\r\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers==4.41.2)\r\n",
      "  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (0.5.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (4.67.1)\r\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.1) (7.0.0)\r\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.1) (2.3.0+cu121)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.2) (2025.5.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.2) (4.14.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.2) (1.1.5)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.41.2) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.41.2) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.41.2) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.41.2) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.41.2) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.41.2) (2.4.1)\r\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.1) (1.13.1)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.1) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.1) (3.1.6)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.1) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.1) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.1) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.1) (8.9.2.26)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.1) (12.1.3.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.1) (11.0.2.54)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.1) (10.3.2.106)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.1) (11.4.5.107)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.1) (12.1.0.106)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.1) (2.20.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.1) (12.1.105)\r\n",
      "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.1) (2.3.0)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.30.1) (12.5.82)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.41.2) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.41.2) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.41.2) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.41.2) (2025.6.15)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.30.1) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.41.2) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.41.2) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers==4.41.2) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers==4.41.2) (2024.2.0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.10.0->accelerate==0.30.1) (1.3.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers==4.41.2) (2024.2.0)\r\n",
      "Downloading transformers-4.41.2-py3-none-any.whl (9.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading accelerate-0.30.1-py3-none-any.whl (302 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading peft-0.11.1-py3-none-any.whl (251 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: tokenizers, transformers, accelerate, peft, bitsandbytes\r\n",
      "  Attempting uninstall: tokenizers\r\n",
      "    Found existing installation: tokenizers 0.21.2\r\n",
      "    Uninstalling tokenizers-0.21.2:\r\n",
      "      Successfully uninstalled tokenizers-0.21.2\r\n",
      "Successfully installed accelerate-0.30.1 bitsandbytes-0.43.1 peft-0.11.1 tokenizers-0.19.1 transformers-4.41.2\r\n",
      "✅ Installation complete. Please restart the runtime now.\n"
     ]
    }
   ],
   "source": [
    "# Uninstall libraries to ensure a clean environment\n",
    "!pip uninstall -y torch torchvision torchaudio transformers accelerate bitsandbytes peft\n",
    "\n",
    "# Install compatible libraries for your GPU\n",
    "!pip install torch==2.3.0 torchvision==0.18.0 torchaudio==2.3.0 --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install transformers==4.41.2 accelerate==0.30.1 bitsandbytes==0.43.1 peft==0.11.1\n",
    "\n",
    "print(\"✅ Installation complete. Please restart the runtime now.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "093b5138",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-07-28T09:59:16.508628Z",
     "iopub.status.busy": "2025-07-28T09:59:16.508184Z",
     "iopub.status.idle": "2025-07-28T09:59:16.650114Z",
     "shell.execute_reply": "2025-07-28T09:59:16.648889Z"
    },
    "id": "WVGP6dfjN4ja",
    "outputId": "3e6e28e7-e9e9-452f-d881-3ac842eb7951",
    "papermill": {
     "duration": 0.234745,
     "end_time": "2025-07-28T09:59:16.651840",
     "exception": false,
     "start_time": "2025-07-28T09:59:16.417095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: nvidia-smi: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a59b248b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-07-28T09:59:16.828527Z",
     "iopub.status.busy": "2025-07-28T09:59:16.828160Z",
     "iopub.status.idle": "2025-07-28T09:59:21.008921Z",
     "shell.execute_reply": "2025-07-28T09:59:21.007196Z"
    },
    "id": "WlaronGHN4jb",
    "outputId": "c2e30700-8a3c-473a-8e86-0b6109620549",
    "papermill": {
     "duration": 4.271266,
     "end_time": "2025-07-28T09:59:21.010380",
     "exception": true,
     "start_time": "2025-07-28T09:59:16.739114",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "LOCAL_NN_MODULE",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13/942959619.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbitsandbytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpeft\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccelerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"0.11.1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m from .auto import (\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mAutoPeftModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mAutoPeftModelForCausalLM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/auto.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m )\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPeftConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmapping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMODEL_TYPE_TO_PEFT_MODEL_MAPPING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m from .peft_model import (\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/config.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPushToHubMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCONFIG_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPeftType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTaskType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mloftq_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreplace_lora_weights_loftq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpeft_types\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPeftType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTaskType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m from .other import (\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mTRANSFORMERS_MODELS_TO_PREFIX_TUNING_POSTPROCESS_MAPPING\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mTRANSFORMERS_MODELS_TO_LORA_TARGET_MODULES_MAPPING\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/utils/other.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0maccelerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0maccelerate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madd_hook_to_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_hook_from_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"0.30.1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAccelerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m from .big_modeling import (\n\u001b[1;32m     18\u001b[0m     \u001b[0mcpu_offload\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcheckpointing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_accelerator_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_custom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_accelerator_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_custom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdata_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoaderDispatcher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepare_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_first_batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAlignDevicesHook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/checkpointing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGradScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m from .utils import (\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mMODEL_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mOPTIMIZER_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbnb\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhas_4bit_bnb_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_and_quantize_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfsdp_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_fsdp_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_fsdp_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_fsdp_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_fsdp_optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m from .launch import (\n\u001b[1;32m    184\u001b[0m     \u001b[0mPrepareForLaunch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/fsdp_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_torch_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\">=\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFSDP_PYTORCH_VERSION\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_torch_distributed_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdist_cp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_planner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDefaultLoadPlanner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDefaultSavePlanner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_sharded_optimizer_state_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCheckpointException\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdefault_planner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDefaultLoadPlanner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDefaultSavePlanner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfilesystem\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFileSystemReader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFileSystemWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfsspec\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFsspecReader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFsspecWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m from .metadata import (\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/distributed/checkpoint/default_planner.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnarrow_tensor_by_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dedup_save_plans\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdedup_save_plans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m from torch.distributed.checkpoint._nested_dict import (\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/distributed/_tensor/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Import all builtin dist tensor ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompute_local_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/distributed/_tensor/ops/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Copyright (c) Meta Platforms, Inc. and affiliates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0membedding_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmatrix_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmath_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtensor_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/distributed/_tensor/ops/embedding_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functional_collectives\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfuncol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m from torch.distributed._tensor.op_schema import (\n\u001b[1;32m     10\u001b[0m     \u001b[0mOpSchema\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/distributed/_functional_collectives.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproxy_tensor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_innermost_proxy_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_functional_collectives_impl\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfun_col_impl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m from ._functional_collectives_impl import (  # noqa: F401\n\u001b[1;32m     14\u001b[0m     \u001b[0m_register_tensor_wrapper\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/distributed/_functional_collectives_impl.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0massume_constant_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0massume_constant_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume_execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlist_backends\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregister_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcallback_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcode_context\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcode_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_traceback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mformat_traceback_short\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace_rules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCompilerFn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbytecode_analysis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mremove_dead_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_pointless_jumps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/trace_rules.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgetfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNP_SUPPORTED_MODULES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munwrap_if_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m from .variables import (\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mBuiltinVariable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mFunctorchHigherOrderVariable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/variables/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# mypy: ignore-errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVariableTracker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbuiltin\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBuiltinVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConstantVariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEnumVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/variables/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_scope_id\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcurrent_scope_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munimplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAttrSource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSource\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mistype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/source.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# so those cases are omitted intentionally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m _GUARD_SOURCE_NN_MODULE = {\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mGuardSource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLOCAL\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mGuardSource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLOCAL_NN_MODULE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mGuardSource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGLOBAL\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mGuardSource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGLOBAL_NN_MODULE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mGuardSource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLOCAL_NN_MODULE\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mGuardSource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLOCAL_NN_MODULE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/enum.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(cls, name)\u001b[0m\n\u001b[1;32m    784\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_member_map_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: LOCAL_NN_MODULE"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import bitsandbytes\n",
    "import peft\n",
    "import accelerate\n",
    "\n",
    "print(\"--- Library Versions ---\")\n",
    "print(f\"Torch: {torch.__version__}\")\n",
    "print(f\"Transformers: {transformers.__version__}\")\n",
    "print(f\"Bitsandbytes: {bitsandbytes.__version__}\")\n",
    "print(f\"PEFT: {peft.__version__}\")\n",
    "print(f\"Accelerate: {accelerate.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae84d33",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aegtWERycn4u",
    "outputId": "0d1a47aa-2b4a-4452-c16c-d5586f2e6496",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "print(f\"Python version: {sys.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a918ab8a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "HyhovyEweaSO",
    "outputId": "9d3e5db3-e972-4d53-eadf-73abd413141c",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip uninstall flash-attn -y\n",
    "!pip install flash-attn==2.5.8 --no-build-isolation # Configured according to CUDA version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90e767a",
   "metadata": {
    "collapsed": true,
    "id": "KkrLg99pe7kY",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c833de1d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 825,
     "referenced_widgets": [
      "369c5c4d309b4b4c8d5515812ef98732",
      "e558a561a6d74bd3a953a3a4529f1488",
      "767b094967974a418821237345b6de05",
      "f68efa1ff8404bfc8c23836c0438b772",
      "87ef8c7244d24d8e83f06a04b300037b",
      "db1496687ec54e56929caab23e572e8c",
      "e63f8d7fa7b4431797aaa45a4d84197c",
      "00b47cec50e84c5da1f9287c50f82053",
      "4c87eb4b1e7144f4981b29987e278dc7",
      "15444290ddf14ed3a9a26f3b2f28d87f",
      "a0d39339f36944b5b4a49c0a4cc3dc26",
      "f80d14c2454441769c3cf7c773283914",
      "c828f4515b8a45b09b19a155ff485864",
      "25cbf0b12a3c4ba9bf51eacf987f3852",
      "e6960b16884a41e5a3ba9b555183fd53",
      "1886db43867c47d5a8dfc026b8c8499b",
      "5cc5f55e053b4a2cb44e013e881db254",
      "4699276dd7704c60b917d53ff7deec8b",
      "f27730d9ce0e4eaa89e791264150443a",
      "cd29fb6c84c140c38d9419d95ae65062",
      "5c64331c54444ab5befb897d66cc3734",
      "edc7a2e0aa0c481184eed60d2cf3a2e0",
      "3afb79a1320944639486a210c2c8207d",
      "ebcab97d657b4579b32f62029fad0f5f",
      "11fe96a42de44cd28052b74b31fecf87",
      "ed1fc648ab9341ae93530c2b299bf31b",
      "a9280442ed1b48e096f85beb5278f43a",
      "11732a30790549a28950f788cb2b79c6",
      "0ef0429548894ee4885733ddf0b151c6",
      "541aac4b314f4eb791e5d6879019354e",
      "94dcf76f9bea45e7b4f8b3a99cb2fa67",
      "3bb7cf89405b47bf9957792e5746695a",
      "a772c4df00f64288aec08e654c7302fe",
      "3e8468c2d7cb48b9a4b2123e3b6d7430",
      "9558965ad0ac44a188acb303746410a1",
      "60aec8c0aa474dad9943584ebb136b26",
      "cd7fcd73b3644db2a7d28ae5bad553f5",
      "9f669d78a61e4900aa43e2e12b6cf2c7",
      "215e1767b4f0489a8067d85abb8c8188",
      "c8648ad0c7744dafa40e417f171d4f9f",
      "e1f47c4cdc5d4c629b5e0c58eb9c35a1",
      "3cee8e19cbd64fa5b75cbbdc081f0335",
      "1e85f14984a146cb800450efcec50ee3",
      "4333781433f84d8a92d05aad0ce1faa2",
      "bc8c7c971e26432c80c138e68d6efd5c",
      "73501b90f6404a899bc7335cd86d14af",
      "42d472029dc645b39d10eebf6f19a940",
      "72a9ec5746204c0e95f4453091a2fac4",
      "0c47376fdd034869990622e6f7d5e01d",
      "e80c93a6d846438db7771e0328ca75ee",
      "b9587f94be7445d2bd0943a68531eb8c",
      "6d12fb5149e04167ba04b30250229f37",
      "f4267121a62d487a8b93d3acabd2a5a3",
      "1b9586b6939a4129b07e902f95e04c13",
      "48a2c7cebfb24f4dbdf844ba4541bab6",
      "15824e0554c24ddf9301a1d710039bd0",
      "fc96040414724c41af3e61aa5b940a8b",
      "8ddeb626a2a44692bf811c81f041ebfd",
      "e739f4186582427d9e7b9cbb7a2bcc77",
      "98af2044825149429ec3a9530811cd6b",
      "ba29102ee24a4322b001bbfcffdbf172",
      "97152476fd3e40fdba7fa0681769b1fa",
      "dbfc48b9b8df44e78e0271a2f2dfee4c",
      "f4e1a57a6a844cbcbbb754421d292b58",
      "22d99b1b4f76479386e57c33f6e886b8",
      "afdc368e98cf44fc9f6b69e4f27d367b",
      "63edaf257b3741c68b3a7a31a73726d5",
      "6089f415cc5a49ac9c7ebb43fe369640",
      "d2405de6d8d84113a5a8b246a5e5dad8",
      "244de2d78d754d4baf47d58678f9903f",
      "896e4ce594044c69a00b3471fac2a66c",
      "6d06199d456048528880f8040b07f322",
      "4e520f68706349e9ac6fb78af2c73041",
      "86ebc3d5d3db467d9ef0ed6debb348fc",
      "710e35e2b80a4b46b481af490b2bfc5d",
      "dbe8796e1674483a8083f626c2e149fc",
      "bc49752ca8fe4e32acf33888046f7b02",
      "5d37298242544ffab74b849401d4f36f",
      "1e67a6536a674e4db1d7adbdee7288d8",
      "75badb87f88e4fcf91cd3c2f174f839e",
      "b0ff5ea4b03247b0840b66e3981cfb12",
      "81bd39c5ab6c43dbbc31388cabcae9fd",
      "a1692a37b2514c9185a133434b4a411e",
      "66a03fcb4c644a09b91378aae9b0732d",
      "35cc5a413dee4db3be72c09f9cb830f9",
      "3c37d118f7bb492e8b3c632c9e140395",
      "c03c9c18352a409b91073aa8b20ae0ad",
      "69d33452d1b4471088c818d1ab8dcadd",
      "f6e7f5aed40347af95bfd126cc2ef76f",
      "4a00fbdf508643f1ac636dc79f427430",
      "7db29f2699d747919377b27c5f08916c",
      "0b49bd491d344d388b3c574e6ca48920",
      "5acc238e1ce24484a698e4c3ee50600b",
      "a8f5737843a94b07b3509b57726f341c",
      "08b08232719b4cb08ddea101e29bd060",
      "7d8a2e21bd324524a750d9c452015836",
      "ece8f02ea5b8494dafb2387a7e300248",
      "481cde6bb0c84fb899cb3c72e9bbb57f",
      "b0ceec60330747f0b40545a84df30d07"
     ]
    },
    "execution": {
     "iopub.execute_input": "2025-07-27T18:35:14.272299Z",
     "iopub.status.busy": "2025-07-27T18:35:14.272008Z",
     "iopub.status.idle": "2025-07-27T18:35:15.522505Z",
     "shell.execute_reply": "2025-07-27T18:35:15.521606Z",
     "shell.execute_reply.started": "2025-07-27T18:35:14.272270Z"
    },
    "id": "lRbtrNhjN4jc",
    "outputId": "f22baf2b-45ff-4022-d400-1a2b52623d93",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers.modeling_utils import PreTrainedModel\n",
    "\n",
    "model_id = \"microsoft/Florence-2-base\"\n",
    "processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)\n",
    "\n",
    "# BitsAndBytes configuration for 4-bit quantization\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# Load the base model with quantization\n",
    "print(\"Loading base model with 4-bit quantization...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=quantization_config,\n",
    "    trust_remote_code=True,\n",
    "    # ignore_mismatched_sizes=True\n",
    "    attn_implementation=\"eager\"  # Use the standard attention implementation\n",
    ")\n",
    "print(\"✅ Base model loaded.\")\n",
    "\n",
    "# LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"dense\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "# Apply the LoRA adapter to the model\n",
    "print(\"\\nApplying LoRA configuration...\")\n",
    "peft_model = get_peft_model(model, lora_config)\n",
    "print(\"✅ LoRA model ready for training.\")\n",
    "\n",
    "# Print the number of trainable parameters\n",
    "print(\"\\nTrainable parameters:\")\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77c70b6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "anO_-jNvd7Zg",
    "outputId": "edbfbbd3-37b3-439e-8a84-e3db9be3f488",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# First, let's examine the structure of your JSON files\n",
    "def examine_json_structure(data_dir=\"/content/generated_data\"):\n",
    "    \"\"\"Examine the structure of your JSON label files\"\"\"\n",
    "    labels_dir = os.path.join(data_dir, \"labels\")\n",
    "    sample_json = os.path.join(labels_dir, \"sample_1.json\")\n",
    "\n",
    "    if os.path.exists(sample_json):\n",
    "        with open(sample_json, 'r') as f:\n",
    "            sample_data = json.load(f)\n",
    "        print(\"Sample JSON structure:\")\n",
    "        print(json.dumps(sample_data, indent=2))\n",
    "        return sample_data\n",
    "    else:\n",
    "        print(\"sample_1.json not found. Available files:\")\n",
    "        print(os.listdir(labels_dir)[:5])\n",
    "        return None\n",
    "\n",
    "# Load and prepare your dataset\n",
    "def load_florence2_data(data_dir=\"/content/generated_data\", task_type=\"OCR\"):\n",
    "    \"\"\"\n",
    "    Load your dataset for Florence-2 training\n",
    "\n",
    "    Args:\n",
    "        data_dir: Path to your data directory\n",
    "        task_type: Type of task - \"OCR\", \"OD\" (Object Detection), \"VQA\", etc.\n",
    "    \"\"\"\n",
    "    images_dir = os.path.join(data_dir, \"images\")\n",
    "    labels_dir = os.path.join(data_dir, \"labels\")\n",
    "\n",
    "    # Get all image files\n",
    "    image_files = sorted(glob.glob(os.path.join(images_dir, \"*.png\")))\n",
    "\n",
    "    dataset = []\n",
    "\n",
    "    for image_path in image_files:\n",
    "        # Get corresponding JSON file\n",
    "        image_name = os.path.basename(image_path).replace('.png', '')\n",
    "        json_path = os.path.join(labels_dir, f\"{image_name}.json\")\n",
    "\n",
    "        if os.path.exists(json_path):\n",
    "            try:\n",
    "                with open(json_path, 'r') as f:\n",
    "                    label_data = json.load(f)\n",
    "\n",
    "                # Process based on task type and JSON structure\n",
    "                if task_type == \"OCR\":\n",
    "                    # For OCR task using your answer data\n",
    "                    task_prompt = \"<OCR>\"\n",
    "\n",
    "                    # Use the answer as OCR target (medical values/text)\n",
    "                    if 'answer' in label_data:\n",
    "                        target = label_data['answer']\n",
    "                    elif 'instruction' in label_data:\n",
    "                        target = label_data['instruction']\n",
    "                    else:\n",
    "                        target = str(label_data)\n",
    "\n",
    "                elif task_type == \"VQA\":\n",
    "                    # For Visual Question Answering\n",
    "                    if 'instruction' in label_data and 'answer' in label_data:\n",
    "                        task_prompt = f\"<VQA>{label_data['instruction']}\"\n",
    "                        target = label_data['answer']\n",
    "                    else:\n",
    "                        continue  # Skip if no instruction/answer data\n",
    "\n",
    "                elif task_type == \"OD\":\n",
    "                    # For Object Detection\n",
    "                    task_prompt = \"<OD>\"\n",
    "\n",
    "                    # Format object detection results\n",
    "                    if 'objects' in label_data:\n",
    "                        objects = label_data['objects']\n",
    "                        target = format_od_target(objects)\n",
    "                    elif 'bboxes' in label_data:\n",
    "                        target = format_bbox_target(label_data)\n",
    "                    else:\n",
    "                        continue  # Skip if no object data\n",
    "\n",
    "                elif task_type == \"VQA\":\n",
    "                    # For Visual Question Answering\n",
    "                    if 'question' in label_data and 'answer' in label_data:\n",
    "                        task_prompt = f\"<VQA>{label_data['question']}\"\n",
    "                        target = label_data['answer']\n",
    "                    else:\n",
    "                        continue  # Skip if no QA data\n",
    "\n",
    "                else:\n",
    "                    # Generic captioning\n",
    "                    task_prompt = \"<CAPTION>\"\n",
    "                    target = str(label_data)\n",
    "\n",
    "                dataset.append({\n",
    "                    'image': image_path,\n",
    "                    'task_prompt': task_prompt,\n",
    "                    'target': target,\n",
    "                    'image_name': image_name\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {json_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "    print(f\"Loaded {len(dataset)} samples for {task_type} task\")\n",
    "    return dataset\n",
    "\n",
    "def format_od_target(objects):\n",
    "    \"\"\"Format object detection target for Florence-2\"\"\"\n",
    "    # Florence-2 expects format: \"<loc_x1><loc_y1><loc_x2><loc_y2>label\"\n",
    "    formatted_objects = []\n",
    "    for obj in objects:\n",
    "        if 'bbox' in obj and 'label' in obj:\n",
    "            bbox = obj['bbox']\n",
    "            label = obj['label']\n",
    "            # Convert bbox to Florence-2 format (normalized coordinates)\n",
    "            formatted_objects.append(f\"<loc_{bbox[0]}><loc_{bbox[1]}><loc_{bbox[2]}><loc_{bbox[3]}>{label}\")\n",
    "\n",
    "    return \" \".join(formatted_objects)\n",
    "\n",
    "def format_bbox_target(label_data):\n",
    "    \"\"\"Format bbox data for Florence-2\"\"\"\n",
    "    # Adjust this based on your specific bbox format\n",
    "    return str(label_data)\n",
    "\n",
    "# Split dataset into train/validation\n",
    "def split_dataset(dataset, test_size=0.2, random_state=42):\n",
    "    \"\"\"Split dataset into train and validation sets\"\"\"\n",
    "    if len(dataset) < 2:\n",
    "        print(\"Dataset too small to split. Using all data for training.\")\n",
    "        return dataset, []\n",
    "\n",
    "    train_data, eval_data = train_test_split(\n",
    "        dataset,\n",
    "        test_size=test_size,\n",
    "        random_state=random_state,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    print(f\"Train samples: {len(train_data)}\")\n",
    "    print(f\"Eval samples: {len(eval_data)}\")\n",
    "\n",
    "    return train_data, eval_data\n",
    "\n",
    "# Main function to prepare your data\n",
    "def prepare_training_data(data_dir=\"/content/generated_data\", task_type=\"OCR\"):\n",
    "    \"\"\"\n",
    "    Complete function to prepare your data for training\n",
    "    \"\"\"\n",
    "    print(\"Examining JSON structure...\")\n",
    "    sample_structure = examine_json_structure(data_dir)\n",
    "\n",
    "    print(f\"\\nLoading data for {task_type} task...\")\n",
    "    dataset = load_florence2_data(data_dir, task_type)\n",
    "\n",
    "    if len(dataset) == 0:\n",
    "        print(\"No data loaded! Please check your JSON structure and task_type.\")\n",
    "        return None, None\n",
    "\n",
    "    print(\"\\nSample data point:\")\n",
    "    print(f\"Image: {dataset[0]['image']}\")\n",
    "    print(f\"Task prompt: {dataset[0]['task_prompt']}\")\n",
    "    print(f\"Target: {dataset[0]['target'][:100]}...\")  # First 100 chars\n",
    "\n",
    "    print(\"\\nSplitting dataset...\")\n",
    "    train_data, eval_data = split_dataset(dataset)\n",
    "\n",
    "    return train_data, eval_data\n",
    "\n",
    "# Usage example:\n",
    "if __name__ == \"__main__\":\n",
    "    # Examine your data structure first\n",
    "    examine_json_structure()\n",
    "\n",
    "    # Load data for OCR task (change task_type as needed)\n",
    "    train_data, eval_data = prepare_training_data(\n",
    "        data_dir=\"/content/generated_data\",\n",
    "        task_type=\"OCR\"  # Change to \"OD\", \"VQA\", etc. based on your data\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cac8989",
   "metadata": {
    "id": "obyNSNuGd8YF",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !ls -R /content/generated_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dca54ef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FgIfVXynkF4j",
    "outputId": "1971390f-2a60-498b-fdc0-c5980fc02456",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!apt-get update && apt-get install -y tesseract-ocr\n",
    "!pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e4bb4a",
   "metadata": {
    "id": "29VjXuV-j6jH",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "def create_ocr_labels_from_images(data_dir=\"/content/generated_data\"):\n",
    "    \"\"\"\n",
    "    Create OCR labels by extracting all text from images using Tesseract\n",
    "    This will give you proper OCR training data\n",
    "    \"\"\"\n",
    "    images_dir = os.path.join(data_dir, \"images\")\n",
    "    ocr_labels_dir = os.path.join(data_dir, \"ocr_labels\")\n",
    "\n",
    "    # Create OCR labels directory\n",
    "    os.makedirs(ocr_labels_dir, exist_ok=True)\n",
    "\n",
    "    # Get all image files\n",
    "    image_files = sorted(glob.glob(os.path.join(images_dir, \"*.png\")))\n",
    "\n",
    "    print(\"Extracting OCR text from images...\")\n",
    "\n",
    "    for i, image_path in enumerate(image_files):\n",
    "        try:\n",
    "            # Load image\n",
    "            image = Image.open(image_path)\n",
    "\n",
    "            # Extract text using Tesseract OCR\n",
    "            extracted_text = pytesseract.image_to_string(image, config='--psm 6')\n",
    "\n",
    "            # Clean up the text\n",
    "            cleaned_text = extracted_text.strip().replace('\\n', ' ').replace('\\t', ' ')\n",
    "            while '  ' in cleaned_text:\n",
    "                cleaned_text = cleaned_text.replace('  ', ' ')\n",
    "\n",
    "            # Save OCR label\n",
    "            image_name = os.path.basename(image_path).replace('.png', '')\n",
    "            ocr_label_path = os.path.join(ocr_labels_dir, f\"{image_name}.json\")\n",
    "\n",
    "            ocr_data = {\n",
    "                \"image\": image_path,\n",
    "                \"ocr_text\": cleaned_text,\n",
    "                \"extraction_method\": \"tesseract\"\n",
    "            }\n",
    "\n",
    "            with open(ocr_label_path, 'w') as f:\n",
    "                json.dump(ocr_data, f, indent=2)\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                print(f\"Processed {i+1}/{len(image_files)} images\")\n",
    "                print(f\"Sample text from {image_name}: {cleaned_text[:100]}...\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_path}: {e}\")\n",
    "\n",
    "    print(f\"OCR labels created in {ocr_labels_dir}\")\n",
    "    return ocr_labels_dir\n",
    "\n",
    "def load_ocr_dataset(data_dir=\"/content/generated_data\", use_generated_ocr=False):\n",
    "    \"\"\"\n",
    "    Load dataset for OCR training\n",
    "\n",
    "    Args:\n",
    "        data_dir: Path to your data directory\n",
    "        use_generated_ocr: If True, use auto-generated OCR labels; if False, use existing answers\n",
    "    \"\"\"\n",
    "    images_dir = os.path.join(data_dir, \"images\")\n",
    "\n",
    "    if use_generated_ocr:\n",
    "        # Use auto-generated OCR labels\n",
    "        labels_dir = os.path.join(data_dir, \"ocr_labels\")\n",
    "        if not os.path.exists(labels_dir):\n",
    "            print(\"OCR labels not found. Creating them...\")\n",
    "            create_ocr_labels_from_images(data_dir)\n",
    "    else:\n",
    "        # Use existing VQA answers as OCR targets\n",
    "        labels_dir = os.path.join(data_dir, \"labels\")\n",
    "\n",
    "    # Get all image files\n",
    "    image_files = sorted(glob.glob(os.path.join(images_dir, \"*.png\")))\n",
    "\n",
    "    dataset = []\n",
    "\n",
    "    for image_path in image_files:\n",
    "        image_name = os.path.basename(image_path).replace('.png', '')\n",
    "        json_path = os.path.join(labels_dir, f\"{image_name}.json\")\n",
    "\n",
    "        if os.path.exists(json_path):\n",
    "            try:\n",
    "                with open(json_path, 'r') as f:\n",
    "                    label_data = json.load(f)\n",
    "\n",
    "                # Extract OCR text based on source\n",
    "                if use_generated_ocr:\n",
    "                    if 'ocr_text' in label_data:\n",
    "                        ocr_text = label_data['ocr_text']\n",
    "                    else:\n",
    "                        continue\n",
    "                else:\n",
    "                    # Use answer from VQA data as OCR text\n",
    "                    if 'answer' in label_data:\n",
    "                        ocr_text = label_data['answer']\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "                # Skip empty text\n",
    "                if not ocr_text or ocr_text.strip() == \"\":\n",
    "                    continue\n",
    "\n",
    "                dataset.append({\n",
    "                    'image': image_path,\n",
    "                    'task_prompt': '<OCR>',\n",
    "                    'target': ocr_text.strip(),\n",
    "                    'image_name': image_name\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {json_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "    print(f\"Loaded {len(dataset)} OCR samples\")\n",
    "    return dataset\n",
    "\n",
    "# Install tesseract if needed\n",
    "def install_tesseract():\n",
    "    \"\"\"Install Tesseract OCR if not available\"\"\"\n",
    "    try:\n",
    "        import pytesseract\n",
    "        pytesseract.image_to_string(Image.new('RGB', (100, 100), 'white'))\n",
    "        print(\"✅ Tesseract already available\")\n",
    "    except:\n",
    "        print(\"Installing Tesseract OCR...\")\n",
    "        os.system(\"apt-get update && apt-get install -y tesseract-ocr\")\n",
    "        os.system(\"pip install pytesseract\")\n",
    "        print(\"✅ Tesseract installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe0c843",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "orsQD5eAkhVI",
    "outputId": "b58e974f-d5e5-4f44-c67c-16a01660402a",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the OCR dataset you just created\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load OCR dataset with proper labels\n",
    "ocr_dataset = load_ocr_dataset(\n",
    "    data_dir=\"/content/generated_data\",\n",
    "    use_generated_ocr=True  # Use the OCR labels you just created\n",
    ")\n",
    "\n",
    "# Split into train/eval\n",
    "train_data, eval_data = train_test_split(\n",
    "    ocr_dataset,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"OCR Training samples: {len(train_data)}\")\n",
    "print(f\"OCR Eval samples: {len(eval_data)}\")\n",
    "\n",
    "# Verify the OCR data looks good\n",
    "for i in range(min(3, len(train_data))):\n",
    "    print(f\"\\nOCR Example {i+1}:\")\n",
    "    print(f\"Image: {os.path.basename(train_data[i]['image'])}\")\n",
    "    print(f\"Task: {train_data[i]['task_prompt']}\")\n",
    "    print(f\"OCR Text: {train_data[i]['target'][:100]}...\")  # First 100 chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4b7a14",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 616
    },
    "id": "UZPt1XUzklHM",
    "outputId": "84d488e8-6b08-4f6f-d814-30ad538388ae",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import os\n",
    "import json\n",
    "from typing import Any, Dict, List\n",
    "from PIL import Image\n",
    "\n",
    "# --- Load your saved dataset ---\n",
    "def load_saved_dataset(image_dir, label_dir):\n",
    "    dataset_list = []\n",
    "    label_files = sorted(os.listdir(label_dir))\n",
    "    for label_file in label_files:\n",
    "        if label_file.endswith('.json'):\n",
    "            image_file = label_file.replace('.json', '.png')\n",
    "            image_path = os.path.join(image_dir, image_file)\n",
    "            label_path = os.path.join(label_dir, label_file)\n",
    "\n",
    "            if os.path.exists(image_path):\n",
    "                with open(label_path, 'r') as f:\n",
    "                    label_data = json.load(f)\n",
    "\n",
    "                # Load the PIL image directly\n",
    "                dataset_list.append({\n",
    "                    \"image\": Image.open(image_path).convert(\"RGB\"),\n",
    "                    \"instruction\": label_data[\"instruction\"],\n",
    "                    \"answer\": label_data[\"answer\"]\n",
    "                })\n",
    "\n",
    "    hf_dataset = Dataset.from_list(dataset_list)\n",
    "    return hf_dataset\n",
    "\n",
    "# Create a proper train/validation split\n",
    "images_dir = \"/content/generated_data/images\"\n",
    "labels_dir = \"/content/generated_data/labels\"\n",
    "full_dataset = load_saved_dataset(images_dir, labels_dir)\n",
    "\n",
    "split_dataset = full_dataset.train_test_split(test_size=0.1)\n",
    "train_dataset = split_dataset['train']\n",
    "eval_dataset = split_dataset['test']\n",
    "\n",
    "print(f\"✅ Loaded and split dataset: {len(train_dataset)} training samples, {len(eval_dataset)} evaluation samples.\")\n",
    "\n",
    "# --- Custom Data Collator ---\n",
    "class FlorenceDataCollator:\n",
    "    def __init__(self, processor):\n",
    "        self.processor = processor\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "        texts = []\n",
    "        for feature in features:\n",
    "            instruction = feature[\"instruction\"]\n",
    "            answer = feature[\"answer\"]\n",
    "            texts.append(f\"Analyze the image and respond to the following task.\\n{instruction}\\n{answer}\")\n",
    "\n",
    "        images = [feature[\"image\"] for feature in features]\n",
    "\n",
    "        inputs = self.processor(text=texts, images=images, return_tensors=\"pt\", padding=True, truncation=True, max_length=1024)\n",
    "\n",
    "        # Manually cast pixel_values to float16 to prevent dtype errors\n",
    "        inputs['pixel_values'] = inputs['pixel_values'].to(torch.float16)\n",
    "\n",
    "        inputs[\"labels\"] = inputs[\"input_ids\"].clone()\n",
    "\n",
    "        return inputs\n",
    "\n",
    "data_collator = FlorenceDataCollator(processor)\n",
    "\n",
    "# --- Training ---\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"florence2_healthcare_finetune\",\n",
    "    num_train_epochs=15,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    warmup_steps=10,\n",
    "    learning_rate=1e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50, # Log less frequently to see progress bar\n",
    "    save_total_limit=2,\n",
    "    do_eval=True, # Enable evaluation\n",
    "    eval_steps=50, # Evaluate every 50 steps\n",
    "    fp16=True,\n",
    "    push_to_hub=False,\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "# Use the standard transformers.Trainer\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "print(\"\\nStarting training...\")\n",
    "trainer.train()\n",
    "print(\"✅ Training complete.\")\n",
    "\n",
    "# Save the final LoRA adapter\n",
    "trainer.save_model(\"florence2_healthcare_final_adapter\")\n",
    "print(\"✅ Final LoRA adapter saved to 'florence2_healthcare_final_adapter'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b833260d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "e4ad8b0f8abe4327be7ebf78780da10a",
      "e960147447db4cd9a37323f4e4f1b6fc",
      "fa75b318a6d44b8c89edc1f3d4935da9",
      "c6a84d5b378547409fdc1803ddb14c22",
      "0eacf611c87249e49eb6511d9a0aac7a",
      "57f27af6a4e0427f9ad39be3cc375ee2",
      "69b353aba9f243db804f458622c770a5",
      "cd9bae87b2ab464da2a4e94b622e78c1",
      "b3a5fe27bd004feeb27116b13d6dee2f",
      "41cf7a21a9644c908b11cda9cc2de256",
      "010e4de85a204e779250755bbcadbe9a",
      "dd2184e256c344c6981fe34f36b9ccc3",
      "cdc8a269f2c848b889d05f912ed5e333",
      "1037fab1667e4fe09b70d2b37cbd1379",
      "a86808901d374dab90006309e36edbb0",
      "a7a414764cf945a08d9c92bb8041234b",
      "2f9feae54a0b46d6a0d2e994e3e2a5e5",
      "b4e92272585c4412acaf02d0925932b4",
      "6bfcb2bfd5ce44699aa82f4f17d90dd0",
      "c9aba8d80ef6400cbd6926216cf141fe",
      "776f84d949e64d25809d054cf3925da9",
      "85cf33b13e714a7d8ea3065e9c6e435a",
      "45b376de356247caadc506750da0a7cf",
      "c32ade2b2ae143499ddeb99160ce477a",
      "f363dac7808c4b3ba42a88cf7a7f741e",
      "3c4ae47480a149dfbe02db8ef811569d",
      "85464a0e56f44d358531c414cd16381e",
      "81e8764a94a54af4bd448a7de20b3959",
      "3cccd3736653474599971ca89a3a56fa",
      "5f6cee4f9a164d14a52f31eb0fd069d4",
      "0762ebf7b5cc4ee1b818363838887e50",
      "b25942424e4a49869128b482255327f5",
      "3b3a4475e9d7483bb179b5f2a80fe18f",
      "d02b0dd3e98c40999e99168557be5065",
      "cc6491944fd14747b61fde211db32608",
      "4f3e1364c9dc44c89a2500327ddde040",
      "9a034f27bf964d9da915b9d024cfcd01",
      "eecb0d3a26824841a26cd1764094616a",
      "bc7390f6849a42c3a74a8d23112ba61e",
      "8333ce7aa41148dfb9b522016b8a524b",
      "4d6dcc86a57a49e9a0c0b855609725ab",
      "0bdc8d44b6214bf0a7ff4daabbee9c3e",
      "6aee39083af54f86b2ef121fbc859ed9",
      "22d5aaef48fb4319a87e9d561e1cd5ea",
      "06b50aac0cf24e81b0e6c46baded9352",
      "3090840720ee4ab8a894d33ffe25e866",
      "31759a73050b4ecea9c9e2fd1eaa84b2",
      "bb03ad539a324be3a4e13b4d2fd6890a",
      "fb60420a08944d0daf484f18e13f34d9",
      "e0611630713643f8b1c56a750d56d49e",
      "4322eb480062410ba49e804dccdc4914",
      "c1e8b017a6d048fea267c35217064dcd",
      "fd0e2de8e68f4e6ea0a3c9b7482336ef",
      "555368c8397b4bc8bca6a64ea2105fae",
      "02622b9290df485d900697a91e613398",
      "b56c2410dd8c4c32819a498612434099",
      "8bbcc84385804baab1bafa26844f2fa8",
      "c38b38882d05422ba105335af76373d7",
      "e94b3be8b828490588947df75abfbd4f",
      "2efea542e2c24bb0a6ae94d9273482fc",
      "8fbd3ee8f676454ca515c14fe8d318f5",
      "130108d34ee0401eab909a1128bc0177",
      "5bfdbad77db1464eb9252052865196c8",
      "881a0c6c2b56453181341c87a461fe5f",
      "e20918fb7a504ec3ab410684c47560f0",
      "5d3faeb40fca4a5b8f7c436590964941",
      "9f59a645f19e4699b8e93e4b050a5830",
      "ecde75105fe848fd96aaab048faf83a4",
      "5794d40d03474e928b92ee72f9a1e953",
      "df603fca6c8240a58f1b06d5fe0bd225",
      "9573c0b3a4c84d758f71d6b6ee2f4729",
      "c35307bfcca94e2ebf9bc06293164b24",
      "a86679250e674f0383f26ba7ecbf8892",
      "95bfd0db331d471799e0f5a17bad3223",
      "45e7e0b2e648462dac7f6e47348cd259",
      "f97dcc3d87aa4d079bf0b4fbcb678442",
      "8e83964099064a3f800cd80911bb7d53"
     ]
    },
    "id": "Ddjq8nSO1OaY",
    "outputId": "893b103e-0eef-4953-f971-d0ee18328547",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "# --- Configuration ---\n",
    "# The original base model ID\n",
    "model_id = \"microsoft/florence-2-base\"\n",
    "\n",
    "# The path where you saved your fine-tuned adapter\n",
    "adapter_path = \"florence2_healthcare_final_adapter\"\n",
    "\n",
    "# The specific task prompt the model was trained on. This MUST match your training setup.\n",
    "# In your training notebook, you used \"<doc_ocr>\".\n",
    "TRAINING_TASK_PROMPT = \"<doc_ocr>\"\n",
    "\n",
    "# --- Load the Fine-Tuned Model for Inference ---\n",
    "# You only need to load the processor once\n",
    "processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)\n",
    "\n",
    "# Load the base model with the same quantization config used for training\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Attach the fine-tuned LoRA adapter to the base model\n",
    "finetuned_model = PeftModel.from_pretrained(base_model, adapter_path)\n",
    "print(\"✅ Fine-tuned model loaded for inference.\")\n",
    "\n",
    "\n",
    "# --- Run a Test Prediction ---\n",
    "# Select a random sample from the unseen evaluation set\n",
    "sample = eval_dataset[random.randint(0, len(eval_dataset) - 1)]\n",
    "image = sample['image']\n",
    "# The ground truth is the full text extracted from the document\n",
    "ground_truth = sample['answer']\n",
    "# The instruction used during training was just the task prompt itself\n",
    "instruction_prompt = TRAINING_TASK_PROMPT\n",
    "\n",
    "# Preprocess the input using the correct prompt format\n",
    "inputs = processor(text=instruction_prompt, images=image, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "# --- Generate the Output ---\n",
    "print(\"\\nGenerating prediction...\")\n",
    "with torch.no_grad():\n",
    "    generated_ids = finetuned_model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        pixel_values=inputs[\"pixel_values\"], # The model handles dtype conversion internally\n",
    "        max_new_tokens=1024, # Increase token limit for full document OCR\n",
    "        num_beams=3,\n",
    "        early_stopping=True\n",
    "    )\n",
    "\n",
    "# Use the processor's post-processing function for robust parsing\n",
    "# The `task` argument MUST match the prompt used for generation\n",
    "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
    "parsed_answer = processor.post_process_generation(generated_text, task=TRAINING_TASK_PROMPT, image_size=(image.width, image.height))\n",
    "\n",
    "\n",
    "# --- Display Results ---\n",
    "print(\"\\n--- Inference Result ---\")\n",
    "print(f\"Task Prompt: {TRAINING_TASK_PROMPT}\")\n",
    "display(image)\n",
    "print(f\"\\nGround Truth Answer:\\n{ground_truth}\")\n",
    "# We access the specific task's output from the parsed dictionary\n",
    "print(f\"\\nModel's Predicted Answer:\\n{parsed_answer.get(TRAINING_TASK_PROMPT, 'Parsing failed')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a132458e",
   "metadata": {
    "id": "DL3KnQ0z3OV_",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "model didnt learn anything - classic case of underfitting \\\n",
    "Increase training samples \\\n",
    "Train on Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113acf2d",
   "metadata": {
    "id": "IVsCwN_U3SFz",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 269.335671,
   "end_time": "2025-07-28T09:59:23.775839",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-28T09:54:54.440168",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "060367f2fa1945debb7676e6ab9743f7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "256efba1da3b45dd8b587fe21c9da516": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "32bcb992e32d436eb5daeea4523314f5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3ba28779dcc84d01978966936d19b3a6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_256efba1da3b45dd8b587fe21c9da516",
       "max": 100.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_32bcb992e32d436eb5daeea4523314f5",
       "tabbable": null,
       "tooltip": null,
       "value": 100.0
      }
     },
     "3ee9908747c5477781ca4f38fc265dbf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_060367f2fa1945debb7676e6ab9743f7",
       "placeholder": "​",
       "style": "IPY_MODEL_d4c1c71004c64eae81aba112c3f8255c",
       "tabbable": null,
       "tooltip": null,
       "value": " 100/100 [00:11&lt;00:00,  8.18it/s]"
      }
     },
     "439a3f8e1322497d97a4e3855159f66e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6705cafb825e46b0b9ffca5aae9505cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_439a3f8e1322497d97a4e3855159f66e",
       "placeholder": "​",
       "style": "IPY_MODEL_835de11f7a9f4e168e62a54c80664183",
       "tabbable": null,
       "tooltip": null,
       "value": "Saving samples: 100%"
      }
     },
     "67a077ebfb9e4c20bf33d4efc2276ace": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6705cafb825e46b0b9ffca5aae9505cf",
        "IPY_MODEL_3ba28779dcc84d01978966936d19b3a6",
        "IPY_MODEL_3ee9908747c5477781ca4f38fc265dbf"
       ],
       "layout": "IPY_MODEL_f8b3a959594e4576bd13e6a3db4c30a0",
       "tabbable": null,
       "tooltip": null
      }
     },
     "835de11f7a9f4e168e62a54c80664183": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d4c1c71004c64eae81aba112c3f8255c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f8b3a959594e4576bd13e6a3db4c30a0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
