{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d360fea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting XlsxWriter\n",
      "  Downloading xlsxwriter-3.2.5-py3-none-any.whl.metadata (2.7 kB)\n",
      "Downloading xlsxwriter-3.2.5-py3-none-any.whl (172 kB)\n",
      "Installing collected packages: XlsxWriter\n",
      "Successfully installed XlsxWriter-3.2.5\n"
     ]
    }
   ],
   "source": [
    "!pip install XlsxWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c30079cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done! File saved as: UHID_Patient_Sheets.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === Step 1: Load files ===\n",
    "\n",
    "# Load audit data (starts from 3rd row)\n",
    "audit_df = pd.read_excel(\"../data/3_Encrypted_Audit_Sample_Cohort_149_Detailed_PCS.xlsx\", header=1)\n",
    "\n",
    "# Detect columns\n",
    "uhid_col = next((col for col in audit_df.columns if \"uhid\" in col.lower()), None)\n",
    "ipno_col = next((col for col in audit_df.columns if \"ipno\" in col.lower()), None)\n",
    "if not uhid_col or not ipno_col:\n",
    "    raise KeyError(\"Missing UHID or IPNO column in audit data.\")\n",
    "\n",
    "audit_df.rename(columns={uhid_col: \"UHID\", ipno_col: \"IPNO\"}, inplace=True)\n",
    "\n",
    "# Load ventilation data\n",
    "vent_df = pd.read_csv(\"../data/Ventilation Data Batch 1.csv\")\n",
    "ipno_vent_col = next((col for col in vent_df.columns if \"ipno\" in col.lower()), None)\n",
    "if not ipno_vent_col:\n",
    "    raise KeyError(\"Missing IPNO column in ventilation data.\")\n",
    "vent_df.rename(columns={ipno_vent_col: \"IPNO\"}, inplace=True)\n",
    "\n",
    "# Load standardized column template\n",
    "standard_df = pd.read_excel(\"../data/Standardized Patient Data Column Headers Jun 30.xlsx\", header=1)\n",
    "standard_cols = [col for col in standard_df.columns if not pd.isna(col)]\n",
    "\n",
    "# === Step 2: Merge audit and ventilation data on IPNO ===\n",
    "merged_df = audit_df.merge(vent_df, on=\"IPNO\", how=\"left\")\n",
    "\n",
    "# === Step 3: Identify extra ventilation columns (excluding IPNO and Total Ventilation Hours) ===\n",
    "vent_extra_cols = [col for col in vent_df.columns if col not in [\"IPNO\", \"Total Ventilation Hours\"]]\n",
    "\n",
    "# === Step 4: Get all unique UHIDs ===\n",
    "uhids = audit_df[\"UHID\"].dropna().unique()\n",
    "\n",
    "# === Step 5: Write Excel with a sheet per UHID ===\n",
    "output_path = \"UHID_Patient_Sheets.xlsx\"\n",
    "with pd.ExcelWriter(output_path, engine=\"xlsxwriter\") as writer:\n",
    "    for uhid in uhids:\n",
    "        df_u = merged_df[merged_df[\"UHID\"] == uhid].copy()\n",
    "\n",
    "        # Get standard columns that exist\n",
    "        final_cols = [col for col in standard_cols if col in df_u.columns]\n",
    "\n",
    "        # Determine which vent_extra_cols are present in this UHID's data\n",
    "        existing_vent_cols = [col for col in vent_extra_cols if col in df_u.columns]\n",
    "\n",
    "        # If any of those columns have non-null values, insert them before Total Ventilation Hours\n",
    "        if existing_vent_cols and not df_u[existing_vent_cols].isnull().all(axis=None):\n",
    "            insert_at = final_cols.index(\"Total Ventilation Hours\") if \"Total Ventilation Hours\" in final_cols else len(final_cols)\n",
    "            for col in reversed(existing_vent_cols):\n",
    "                final_cols.insert(insert_at, col)\n",
    "\n",
    "\n",
    "        # Save to Excel sheet (limit to 31 characters)\n",
    "        df_u[final_cols].to_excel(writer, sheet_name=str(uhid)[:31], index=False)\n",
    "\n",
    "print(f\"✅ Done! File saved as: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62b2a16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eda6e9fa-b9b5-4e8c-bbe7-69dd3777d622', '29d84ac3-dccf-4980-99b2-0e743999ed60', 1, 89, '2023-07-06 07:18:14', '2023-07-08 12:42:09', 2, 'NON-AICVD', 5, 0, '0.1', '1.1', 'Discharged to home or self care (Routine Discharge)', 'CERVICAL SPONDOLYSIS', ' <PER> came to ED with aforementioned complaints. On arrival to ED his saturation was 65% in RA, PR-104/min and   blood pressure-180/100mmHg.On Chest auscultation,  bilateral crackles(+) .Chest Xray showed features of acute Pulmonary edema. He was started on with NTG infusion, NIV support and IV diuretics. He was transferred to CCU for further evaluation and management. ECHO showed dilated LA, RWMA, Moderate LV systolic dysfunction, mild MR, mild TR. Pulmonology opinion was taken in view of  X-Ray changes and Co2 Retention in ABG and advised nebulization.\\n\\nNIV, NTG and Lasix infusions were weaned off gradually as patient started clinically improving. Patient became symptomatically better and was shifted out to room. He was treated with antiplatelet, statin, betablocker, diuretics, nebulizations and other supportive measures. At the time of discharge his vitals stable, hemodynamically better, hence being discharged with following advices.', 'J810', 'U', 'J9601 | I5189 | R931 | I429 | I340 | I361', 'U | U | U | U | U | U', 'CAG:-RRA\\nLMCA   :-4.5mm, Bifurcates, Normal :\\nLAD      :-3.5mm, Type III vessel, Proximal LAD discrete 50% disease\\nLCX      : 2.75mm, Non dominant, Patent stent in LCx\\nRCA     : 3mm, Dominant, No flow limiting lesion, PDA &amp; PLB Normal :\\nFinal Diagnosis : SVD\\nRecommendation : OMT', 'Unnamed: 20', 'Unnamed: 21', 'Unnamed: 22', 'Unnamed: 23', 'Unnamed: 24', 'Unnamed: 25', '5A09357 | 3E0F3SD', '5A09357', 'Extracorporeal or Systemic Assistance and Performance', 'Physiological Systems', 'Assistance', 'Respiratory', 'Less than 24 Consecutive Hours', '3E0F3SD', 'Administration', 'Physiological Systems and Anatomical Regions', 'Introduction', 'Respiratory Tract', 'Percutaneous', 'Unnamed: 39', 'Unnamed: 40', 'Unnamed: 41', 'Unnamed: 42', 'Unnamed: 43', 'Unnamed: 44', 'Unnamed: 45', 'Unnamed: 46', 'Unnamed: 47', 'Unnamed: 48', 'Unnamed: 49', 'Unnamed: 50', 'Unnamed: 51', 'Unnamed: 52', 'Unnamed: 53', 'Unnamed: 54', 'Unnamed: 55', 'Unnamed: 56', 'Unnamed: 57', 'Unnamed: 58', 'Unnamed: 59', 'Unnamed: 60', 'Unnamed: 61', 'Unnamed: 62']\n"
     ]
    }
   ],
   "source": [
    "print(audit_df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b951ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚠️ Missing Columns in UHID Sheet (present in Standard Template):\n",
      "\n",
      "  - LABEL\n",
      "  - SPECIALITY\n",
      "  - CASESPLIT\n",
      "  - SURGERYDATE\n",
      "  - PATIENT_TYPE\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === File Paths ===\n",
    "uhid_file_path = \"../code/UHID_Patient_Sheets.xlsx\"\n",
    "standard_file_path = \"../data/Standardized Patient Data Column Headers Jun 30.xlsx\"\n",
    "\n",
    "# === Load the First Sheet from the UHID Excel File ===\n",
    "uhid_excel = pd.ExcelFile(uhid_file_path)\n",
    "uhid_df = pd.read_excel(uhid_excel, sheet_name=uhid_excel.sheet_names[0])\n",
    "uhid_columns = uhid_df.columns.tolist()\n",
    "\n",
    "# === Load Standard Columns from Template (header on 2nd row → header=1) ===\n",
    "standard_df = pd.read_excel(standard_file_path, header=1)\n",
    "standard_columns = [col for col in standard_df.columns if not pd.isna(col)]\n",
    "\n",
    "# === Identify Columns Missing in UHID Data ===\n",
    "missing_columns = [col for col in standard_columns if col not in uhid_columns]\n",
    "\n",
    "# === Output Results ===\n",
    "print(\"\\n⚠️ Missing Columns in UHID Sheet (present in Standard Template):\\n\")\n",
    "for col in missing_columns:\n",
    "    print(f\"  - {col}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "442d18f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done! Filtered file saved to: UHID_Patient_Sheets_Filtered.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the multi-sheet Excel file\n",
    "input_path = \"UHID_Patient_Sheets.xlsx\"\n",
    "output_path = \"UHID_Patient_Sheets_Filtered.xlsx\"\n",
    "\n",
    "# Load all sheets\n",
    "all_sheets = pd.read_excel(input_path, sheet_name=None, engine=\"openpyxl\")\n",
    "\n",
    "# Get all ventilation-related column names\n",
    "# We'll collect from all sheets to be sure\n",
    "ventilation_keywords = ['ventilation', 'ventilator']\n",
    "vent_cols_set = set()\n",
    "\n",
    "for sheet, df in all_sheets.items():\n",
    "    for col in df.columns:\n",
    "        col_lower = col.lower()\n",
    "        if any(key in col_lower for key in ventilation_keywords) and col != \"Total Ventilation Hours\":\n",
    "            ventilation_col = col.strip()\n",
    "            ventilation_col = ventilation_col.replace(\"\\n\", \" \").strip()\n",
    "            ventilation_col = ventilation_col.replace(\"  \", \" \")\n",
    "            ventilation_col = ventilation_col.strip()\n",
    "            ventilation_col = ventilation_col.strip(\".\")\n",
    "            ventilation_col = ventilation_col.strip(\"_\")\n",
    "            ventilation_col = ventilation_col.strip(\"-\")\n",
    "            vent_cols_set.add(ventilation_col)\n",
    "\n",
    "vent_cols = list(vent_cols_set)\n",
    "\n",
    "# Create output Excel\n",
    "os.makedirs(\"code\", exist_ok=True)\n",
    "with pd.ExcelWriter(output_path, engine=\"openpyxl\") as writer:\n",
    "    for sheet_name, df in all_sheets.items():\n",
    "        if \"Total Ventilation Hours\" not in df.columns or df[\"Total Ventilation Hours\"].isnull().all():\n",
    "            # Drop all vent columns if 'Total Ventilation Hours' is missing or all null\n",
    "            df = df.drop(columns=[col for col in vent_cols if col in df.columns], errors='ignore')\n",
    "            df = df.drop(columns=[\"Total Ventilation Hours\"], errors='ignore')\n",
    "\n",
    "        df.to_excel(writer, sheet_name=sheet_name[:31], index=False)\n",
    "\n",
    "print(f\"✅ Done! Filtered file saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83e4f00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done! File saved as: UHID_Patient_Sheets_Filtered.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === Step 1: Load files ===\n",
    "\n",
    "# Load audit data (starts from 3rd row)\n",
    "audit_df = pd.read_excel(\"../data/3_Encrypted_Audit_Sample_Cohort_149_Detailed_PCS.xlsx\", header=1)\n",
    "\n",
    "# Detect columns\n",
    "uhid_col = next((col for col in audit_df.columns if \"uhid\" in col.lower()), None)\n",
    "ipno_col = next((col for col in audit_df.columns if \"ipno\" in col.lower()), None)\n",
    "if not uhid_col or not ipno_col:\n",
    "    raise KeyError(\"Missing UHID or IPNO column in audit data.\")\n",
    "\n",
    "audit_df.rename(columns={uhid_col: \"UHID\", ipno_col: \"IPNO\"}, inplace=True)\n",
    "\n",
    "# Load ventilation data\n",
    "vent_df = pd.read_csv(\"../data/Ventilation Data Batch 1.csv\")\n",
    "ipno_vent_col = next((col for col in vent_df.columns if \"ipno\" in col.lower()), None)\n",
    "if not ipno_vent_col:\n",
    "    raise KeyError(\"Missing IPNO column in ventilation data.\")\n",
    "vent_df.rename(columns={ipno_vent_col: \"IPNO\"}, inplace=True)\n",
    "\n",
    "# Get list of IPNOs with ventilation data\n",
    "vent_ipnos = set(vent_df[\"IPNO\"].dropna().astype(str))\n",
    "\n",
    "# Load standardized column template\n",
    "standard_df = pd.read_excel(\"../data/Standardized Patient Data Column Headers Jun 30.xlsx\", header=1)\n",
    "standard_cols = [col for col in standard_df.columns if not pd.isna(col)]\n",
    "\n",
    "# === Step 2: Merge audit and ventilation data on IPNO ===\n",
    "merged_df = audit_df.merge(vent_df, on=\"IPNO\", how=\"left\")\n",
    "\n",
    "# === Step 3: Define ventilation-related columns ===\n",
    "vent_all_cols = [\n",
    "    \"use_1_start\", \"use_1_end\", \"use_1_duration\",\n",
    "    \"use_2_start\", \"use_2_end\", \"use_2_duration\",\n",
    "    \"use_3_start\", \"use_3_end\", \"use_3_duration\",\n",
    "    \"use_4_start\", \"use_4_end\", \"use_4_duration\",\n",
    "    \"use_5_start\", \"use_5_end\", \"use_5_duration\",\n",
    "    \"use_6_start\", \"use_6_end\", \"use_6_duration\",\n",
    "    \"use_7_start\", \"use_7_end\", \"use_7_duration\",\n",
    "    \"DMV_DOA\", \"total_uses\", \"total_duration_hours\"\n",
    "]\n",
    "\n",
    "# Always delete these columns even if ventilated\n",
    "always_delete = [\n",
    "    \"use_6_start\", \"use_6_end\", \"use_6_duration\",\n",
    "    \"use_7_start\", \"use_7_end\", \"use_7_duration\"\n",
    "]\n",
    "\n",
    "# === Step 4: Get all unique UHIDs ===\n",
    "uhids = audit_df[\"UHID\"].dropna().unique()\n",
    "\n",
    "# === Step 5: Write Excel with a sheet per UHID ===\n",
    "output_path = \"UHID_Patient_Sheets_Filtered.xlsx\"\n",
    "with pd.ExcelWriter(output_path, engine=\"xlsxwriter\") as writer:\n",
    "    for uhid in uhids:\n",
    "        df_u = merged_df[merged_df[\"UHID\"] == uhid].copy()\n",
    "\n",
    "        # Get IPNO for this UHID (assume one IPNO per UHID for now)\n",
    "        ipno = str(df_u[\"IPNO\"].iloc[0])\n",
    "\n",
    "        # Start with all standard columns that are present in df_u\n",
    "        final_cols = [col for col in standard_cols if col in df_u.columns]\n",
    "\n",
    "        # Always delete use_6 and use_7 related columns\n",
    "        final_cols = [col for col in final_cols if col not in always_delete]\n",
    "\n",
    "        # If IPNO not in ventilation list, drop other ventilation cols too\n",
    "        if ipno not in vent_ipnos:\n",
    "            final_cols = [col for col in final_cols if col not in vent_all_cols]\n",
    "\n",
    "        # Save to Excel sheet (limit to 31 characters)\n",
    "        df_u[final_cols].to_excel(writer, sheet_name=str(uhid)[:31], index=False)\n",
    "\n",
    "print(f\"✅ Done! File saved as: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4dd217b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Updated file saved as: UHID_Patient_Sheets_Final.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === Step 1: Load additional data ===\n",
    "discharges_df = pd.read_excel(\"../data/1_Raw_Encrypted_Data.xlsx\", sheet_name=\"Discharges_Data\")\n",
    "surgery_df = pd.read_excel(\"../data/1_Raw_Encrypted_Data.xlsx\", sheet_name=\"Surgery_Data\")\n",
    "\n",
    "# Ensure UHID column names are consistent\n",
    "uhid_col_discharges = next((col for col in discharges_df.columns if \"uhid\" in col.lower()), None)\n",
    "uhid_col_surgery = next((col for col in surgery_df.columns if \"uhid\" in col.lower()), None)\n",
    "\n",
    "discharges_df.rename(columns={uhid_col_discharges: \"UHID\"}, inplace=True)\n",
    "surgery_df.rename(columns={uhid_col_surgery: \"UHID\"}, inplace=True)\n",
    "\n",
    "# Extract required columns only\n",
    "discharges_df = discharges_df[[\"UHID\", \"SPECIALITY\", \"CASESPLIT\"]].drop_duplicates()\n",
    "surgery_df = surgery_df[[\"UHID\", \"SURGERYDATE\"]].drop_duplicates()\n",
    "\n",
    "# === Step 2: Load existing filtered Excel with all UHID sheets ===\n",
    "input_file = \"UHID_Patient_Sheets_Filtered.xlsx\"\n",
    "output_file = \"UHID_Patient_Sheets_Final.xlsx\"\n",
    "\n",
    "with pd.ExcelFile(input_file) as reader, pd.ExcelWriter(output_file, engine=\"xlsxwriter\") as writer:\n",
    "    for sheet_name in reader.sheet_names:\n",
    "        df = reader.parse(sheet_name)\n",
    "\n",
    "        # Extract UHID from sheet name\n",
    "        uhid = sheet_name\n",
    "\n",
    "        # Merge SPECIALITY, CASESPLIT\n",
    "        df = df.merge(discharges_df, on=\"UHID\", how=\"left\")\n",
    "\n",
    "        # Merge SURGERY Date\n",
    "        df = df.merge(surgery_df, on=\"UHID\", how=\"left\")\n",
    "\n",
    "        # Save updated sheet\n",
    "        df.to_excel(writer, sheet_name=sheet_name[:31], index=False)\n",
    "\n",
    "print(f\"✅ Updated file saved as: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c395afe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final formatted Excel saved as: UHID_Patient_Sheets_Formatted.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "\n",
    "# === Step 1: Load standard multi-row column header file ===\n",
    "header_df = pd.read_excel(\"../data/Standardized Patient Data Column Headers Jun 30.xlsx\", header=[0, 1])\n",
    "multiindex_cols = header_df.columns\n",
    "\n",
    "# Map: detailed column name -> category\n",
    "col_mapping = {detailed: category for category, detailed in multiindex_cols if not pd.isna(detailed)}\n",
    "\n",
    "# Ordered list of standard columns (detailed only)\n",
    "standard_order = [detailed for (_, detailed) in multiindex_cols if not pd.isna(detailed)]\n",
    "\n",
    "# === Step 2: Load UHID_Patient_Sheets_Final and format ===\n",
    "input_file = \"UHID_Patient_Sheets_Final.xlsx\"\n",
    "output_file = \"UHID_Patient_Sheets_Formatted.xlsx\"\n",
    "\n",
    "with pd.ExcelFile(input_file) as reader, pd.ExcelWriter(output_file, engine=\"xlsxwriter\") as writer:\n",
    "    for sheet_name in reader.sheet_names:\n",
    "        df = reader.parse(sheet_name)\n",
    "\n",
    "        # Split columns into standard and extra\n",
    "        available_cols = [col for col in standard_order if col in df.columns]\n",
    "        extra_cols = [col for col in df.columns if col not in standard_order]\n",
    "\n",
    "        # Final column order: standard + extra\n",
    "        final_cols = available_cols + extra_cols\n",
    "        df = df[final_cols]\n",
    "\n",
    "        # Build category and detailed headers\n",
    "        detailed_headers = final_cols\n",
    "        category_headers = [col_mapping.get(col, \"\") for col in detailed_headers]\n",
    "\n",
    "        # Write data starting from row 2\n",
    "        df.to_excel(writer, sheet_name=sheet_name[:31], index=False, startrow=2, header=False)\n",
    "\n",
    "        # Write category and detailed header rows\n",
    "        worksheet = writer.sheets[sheet_name[:31]]\n",
    "\n",
    "        for col_idx, (cat, colname) in enumerate(zip(category_headers, detailed_headers)):\n",
    "            worksheet.write(0, col_idx, cat)\n",
    "            worksheet.write(1, col_idx, colname)\n",
    "\n",
    "        # Merge same category cells (visual only)\n",
    "        grouped = [(key, list(group)) for key, group in groupby(enumerate(category_headers), key=lambda x: x[1])]\n",
    "        for category, group in grouped:\n",
    "            indices = [i for i, _ in group]\n",
    "            if category and len(indices) > 1:\n",
    "                worksheet.merge_range(0, indices[0], 0, indices[-1], category)\n",
    "\n",
    "print(f\"✅ Final formatted Excel saved as: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9beaf69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All individual Excel files saved with flattened headers.\n",
      "✅ All files zipped into: All_Patient_Files.zip\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# === Config ===\n",
    "input_file = \"UHID_Patient_Sheets_Formatted.xlsx\"\n",
    "output_dir = \"individual_patients\"\n",
    "zip_file = \"All_Patient_Files.zip\"\n",
    "\n",
    "# === Step 1: Create output directory ===\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# === Step 2: Read and save each sheet with flattened headers ===\n",
    "with pd.ExcelFile(input_file) as reader:\n",
    "    for i, sheet_name in enumerate(reader.sheet_names, start=1):\n",
    "        df = reader.parse(sheet_name, header=[0, 1])  # MultiIndex\n",
    "\n",
    "        # Flatten MultiIndex columns\n",
    "        df.columns = [' - '.join([str(level) for level in col if str(level) != 'nan']).strip() for col in df.columns]\n",
    "\n",
    "        # Save as Patient1.xlsx, Patient2.xlsx, ...\n",
    "        out_filename = os.path.join(output_dir, f\"Patient{i}.xlsx\")\n",
    "        df.to_excel(out_filename, index=False)\n",
    "\n",
    "print(\"✅ All individual Excel files saved with flattened headers.\")\n",
    "\n",
    "# === Step 3: Zip all Excel files ===\n",
    "with zipfile.ZipFile(zip_file, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for filename in os.listdir(output_dir):\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        zipf.write(filepath, arcname=filename)\n",
    "\n",
    "print(f\"✅ All files zipped into: {zip_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e60dfce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All individual Excel files saved exactly as-is.\n",
      "✅ Zipped to: All_Patient_Files.zip\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# === Config ===\n",
    "input_file = \"UHID_Patient_Sheets_Formatted.xlsx\"\n",
    "output_dir = \"individual_patients\"\n",
    "zip_file = \"All_Patient_Files.zip\"\n",
    "\n",
    "# === Step 1: Create output directory ===\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# === Step 2: Read and save each sheet EXACTLY as-is ===\n",
    "with pd.ExcelFile(input_file) as reader:\n",
    "    for i, sheet_name in enumerate(reader.sheet_names, start=1):\n",
    "        df = reader.parse(sheet_name, header=[0, 1])  # ✅ preserves two-level header\n",
    "\n",
    "        out_filename = os.path.join(output_dir, f\"Patient{i}.xlsx\")\n",
    "        \n",
    "        # ✅ Write MultiIndex headers with index=True to avoid Pandas bug\n",
    "        df.to_excel(out_filename, index=True)  # index=True is required for MultiIndex header write\n",
    "\n",
    "print(\"✅ All individual Excel files saved exactly as-is.\")\n",
    "\n",
    "# === Step 3: Zip the files ===\n",
    "with zipfile.ZipFile(zip_file, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for filename in os.listdir(output_dir):\n",
    "        if filename.endswith(\".xlsx\"):\n",
    "            filepath = os.path.join(output_dir, filename)\n",
    "            zipf.write(filepath, arcname=filename)\n",
    "\n",
    "print(f\"✅ Zipped to: {zip_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
